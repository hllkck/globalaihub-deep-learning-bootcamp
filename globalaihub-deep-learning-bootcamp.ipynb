{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2170465,"sourceType":"datasetVersion","datasetId":1165452}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-24T15:47:59.011287Z","iopub.execute_input":"2024-10-24T15:47:59.011774Z","iopub.status.idle":"2024-10-24T15:47:59.313739Z","shell.execute_reply.started":"2024-10-24T15:47:59.011736Z","shell.execute_reply":"2024-10-24T15:47:59.312837Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label = []  \npath = []  \nfish_dir = '/kaggle/input/a-large-scale-fish-dataset/Fish_Dataset/Fish_Dataset'  \nfor dir_name, _, filenames in os.walk(fish_dir):  \n for filename in filenames:  \n     if os.path.splitext(filename)[-1] == '.png': \n         if dir_name.split()[-1]!='GT':  # finds the \"GT\" in the directory names from reverse \n             label.append(os.path.split(dir_name)[-1])  \n             path.append(os.path.join(dir_name, filename))\n\ndata=pd.DataFrame(columns=['path','label'])\ndata['path'] = path\ndata['label'] = label\nprint(data.shape) \nprint(data['label'].unique()) #class number\n#print(label,'/n')\n#print(path[:3])","metadata":{"execution":{"iopub.status.busy":"2024-10-24T15:47:59.320575Z","iopub.execute_input":"2024-10-24T15:47:59.321223Z","iopub.status.idle":"2024-10-24T15:47:59.453640Z","shell.execute_reply.started":"2024-10-24T15:47:59.321181Z","shell.execute_reply":"2024-10-24T15:47:59.452652Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This code block parses the images and labels from the datasets file paths for use in later stages. Then, it saves them in 2 separate arrays named path[] and label[].\nThe first output shows that there are 9000 data in the dataset and 2 columns: path, label. The second output shows 9 different classes to be used in the classification.","metadata":{}},{"cell_type":"code","source":"import os\nprint(os.listdir('/kaggle/input'))\nfrom PIL import Image\nimport os\n\nimage_directory = '/kaggle/input/a-large-scale-fish-dataset/Fish_Dataset/Fish_Dataset'\n\n# used os.walk to check images in subfolders too\nfor root, dirs, files in os.walk(image_directory):\n    for filename in files:\n        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n            image_path = os.path.join(root, filename)\n            try:\n                with Image.open(image_path) as img:\n                    width, height = img.size\n                    print(f'{filename}: {width}x{height}')\n            except Exception as e:\n                print(f'The image could not be read: {filename}, Error: {e}')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T15:47:59.454832Z","iopub.execute_input":"2024-10-24T15:47:59.455132Z","iopub.status.idle":"2024-10-24T15:48:21.062000Z","shell.execute_reply.started":"2024-10-24T15:47:59.455100Z","shell.execute_reply":"2024-10-24T15:48:21.061044Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**This code block was written to set the dimensions of the images to be used in model training.**\r\nThe file extensions of the images in the dataset are checked using the file path, then the dimensions of the images are determined with the size() function and printed to the screen. After checking the dimensions, the appropriate X*X size to be given to the model is decided.\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport cv2\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\n\ndataset_path = '/kaggle/input/a-large-scale-fish-dataset/Fish_Dataset/Fish_Dataset'\n\nimages = []\nlabels = []\n\n# determine the image dimensions\nimg_width, img_height = 128, 128\n            \n# looped subfolders in the main folder for each fish species\nfor fish_type in os.listdir(dataset_path):\n    fish_type_path = os.path.join(dataset_path, fish_type)\n    \n    # fish species folder control\n    if os.path.isdir(fish_type_path):\n        for subfolder in os.listdir(fish_type_path):\n            subfolder_path = os.path.join(fish_type_path, subfolder)\n            \n            # subfolder control\n            if os.path.isdir(subfolder_path) and not subfolder.endswith('GT'):\n                for img_name in os.listdir(subfolder_path):\n                    if not img_name.lower().endswith(('.png', '.jpg', '.jpeg')) :\n                        continue\n                    \n                    img_path = os.path.join(subfolder_path, img_name)\n                    img = cv2.imread(img_path)\n                    \n                    if img is None:\n                        continue\n                    \n                    img = cv2.resize(img, (img_width, img_height))\n                    img = img / 255.0  # normalization\n                    images.append(img)\n                    labels.append(fish_type) \n\n# convert to NumPy arrays\nimages = np.array(images)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels) # numbered the series alphabetically\ny = to_categorical(labels)  # make it categorical (it prints 1 to the class it belongs to)\nprint(f'Images size: {images.shape}')  # expected size (n, 128, 128, 3)\nprint(f'Label size: {y.shape}')   # expected size (n, 9) \n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T15:48:21.064497Z","iopub.execute_input":"2024-10-24T15:48:21.064997Z","iopub.status.idle":"2024-10-24T15:49:41.255644Z","shell.execute_reply.started":"2024-10-24T15:48:21.064952Z","shell.execute_reply":"2024-10-24T15:49:41.254700Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In this code block, the images in the dataset are resized to 128x128. The images are normalized for use in model training; this step is important because neural networks work better with values ​​between 0 and 1. The normalized images are added to the images list, while the fish species labels are added to the labels list. Both the images and labels lists are then converted to NumPy arrays. LabelEncoder is used to sort the labels alphabetically and convert them to numerical values. Then, the to_categorical() function converts these numerical labels into a vector representing each class, bringing them to categorical form (for example, [0 0 0 0 0 0 0 0 1] for class number 9).The size of the images determined using the (images.shape) function. The output (n, 128, 128, 3) shows that there are n 128x128 3-channel (RGB) images. n represents the number of samples here, there are 9000 samples in our study.The size of the labels (y.shape) is printed on the screen. The output (n, 9) shows that there are n images and 9 classes. \r.","metadata":{}},{"cell_type":"code","source":"#X = images.reshape(images.shape[0], -1)\n#print(X.shape[1])","metadata":{"execution":{"iopub.status.busy":"2024-10-24T15:49:41.256773Z","iopub.execute_input":"2024-10-24T15:49:41.257069Z","iopub.status.idle":"2024-10-24T15:49:41.261510Z","shell.execute_reply.started":"2024-10-24T15:49:41.257037Z","shell.execute_reply":"2024-10-24T15:49:41.260511Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**X = images.reshape(images.shape[0], -1) Why is it done?**\n\nMachine learning models generally take data in two dimensions; in the form of the number of samples and the number of features. However, since the images are three-dimensional or more, it is necessary to convert each image into a one-dimensional vector. This allows the model to process this data more easily. This transformation is done to put the data in a proper format before entering the neural network.","metadata":{}},{"cell_type":"code","source":"\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten\n\n\nX = images.reshape(images.shape[0], -1)  # (9000, 49152)\n\n# create training, temporary, and temporary subsets\nX_train, X_temporary, y_train, y_temporary = train_test_split(X, y, train_size=0.8)\n\n# create validation and test subsets\nX_val, X_test, y_val, y_test = train_test_split(X_temporary, y_temporary, train_size=0.6)\n\n\n# create model object\nmodel = tf.keras.Sequential()\n# create input layer\ninput_layer = tf.keras.layers.Dense(128, input_shape=(X.shape[1],), activation='relu') \nmodel.add(input_layer)\nmodel.add(tf.keras.layers.Dense(256, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.3))\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.3))\nmodel.add(tf.keras.layers.Dense(64, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.3))\n# add output layer\nmodel.add(tf.keras.layers.Dense(9, activation='softmax'))\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nresults = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=128, callbacks=[early_stopping])\n\n# draw train loss\nplt.plot(results.history['loss'], label='Train')\n# draw validation loss\nplt.plot(results.history['val_loss'], label='Test')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T15:49:41.264348Z","iopub.execute_input":"2024-10-24T15:49:41.264683Z","iopub.status.idle":"2024-10-24T15:50:30.780621Z","shell.execute_reply.started":"2024-10-24T15:49:41.264651Z","shell.execute_reply":"2024-10-24T15:50:30.779634Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In this code block, images with dimensions of 128x128 and 3 color channels are flattened and converted into a single line. With this process, an X series of 9000 images is created, where each image consists of 49152 pixels. Then, the data is divided into 80% training and 20% temporary data set. The temporary data set is divided into 60% validation and 40% test data. The divided data sets are carried to the model creation stage. First, an input layer of 128 neurons with an input size of 49152 is used and this layer has an activation function called \"relu\". Then, 3 layers with 256, 128 and 64 neurons are added and each layer is accompanied by a Dropout layer where 30% of the neurons will be disabled. Finally, an output layer using the \"softmax\" activation function is added. The reason for using \"softmax\" is that it is used in multi-class classifications.\n\nAdam optimizer is used for model optimization and the learning rate is set to 0.0001. Categorical_crossentropy is selected as the loss function and accuracy is selected as the performance measurement. Epoch value is set to 50 and batch_size is set to 128 in each epoch. With the early stopping method, if the validation loss does not improve for 5 epochs, training is stopped and the best weights are restored.\n\nThen, the loss values ​​in the training and validation process are visualized by naming the axes as \"Epoch\" and \"Loss\". Thanks to this graph, the performance of the model during the training period and its progress in the validation data can be examined.","metadata":{}},{"cell_type":"code","source":"# evaluate the performance\ntest_result = model.test_on_batch(X_test, y_test)\n# print the result\nprint(test_result)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T15:50:30.786478Z","iopub.execute_input":"2024-10-24T15:50:30.787365Z","iopub.status.idle":"2024-10-24T15:50:39.958032Z","shell.execute_reply.started":"2024-10-24T15:50:30.787316Z","shell.execute_reply":"2024-10-24T15:50:39.957118Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Here, the test_on_batch(X_test, y_test) function evaluates the model on the test datasets X_test and y_test in one go (batch). The metrics of the model such as loss and accuracy are returned.So this code allows us to quickly see the performance of the model on test data.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\n# evaluate the performance of the model using test data\npredictions = model.predict(X)\npredicted_classes = np.argmax(predictions, axis=1)  # select classes based on highest probabilities\n\ntrue_classes = np.argmax(y, axis=1)\n\nprint(\"Classification Report:\")\nprint(classification_report(true_classes, predicted_classes, target_names=le.classes_))\n\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(true_classes, predicted_classes))","metadata":{"execution":{"iopub.status.busy":"2024-10-24T15:50:39.959198Z","iopub.execute_input":"2024-10-24T15:50:39.959497Z","iopub.status.idle":"2024-10-24T15:50:45.759727Z","shell.execute_reply.started":"2024-10-24T15:50:39.959466Z","shell.execute_reply":"2024-10-24T15:50:45.758755Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In this code snippet, the classification report and confusion matrix are used to evaluate the performance of the trained model on the test data.\nThe predict(X) function allows the model to make predictions for all images. This returns an array containing the probability values for each fish species.\nUsing np.argmax(predictions, axis=1), the highest predicted probabilities are selected and assigned to the predicted_classes array as predicted classes.\nUsing np.argmax(y, axis=1), the numerical equivalents of the true labels (i.e. the correct classes) are assigned to the true_classes array.\nUsing classification_report(true_classes, predicted_classes, target_names=le.classes_), a report summarizing the performance of the model is generated. This report contains metrics such as accuracy, recall, and F1 score for each class. The class names are added with target_names.\nThe confusion_matrix(true_classes, predicted_classes) command creates and prints a confusion matrix that visually represents the model’s correct and incorrect predictions. This matrix shows how accurately each class was predicted and which classes were confused. These steps are used to evaluate the model’s overall success and its performance for each class.","metadata":{}}]}